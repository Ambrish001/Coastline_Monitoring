{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFkToQZ1kSLeFltrQ9GKSI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ambrish001/Coastline_Monitoring/blob/main/Final_Notebook_UCD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the necessary libraries"
      ],
      "metadata": {
        "id": "T9yURrfM4tpU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DMv4OINR4Hd1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import imutils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting Google Drive"
      ],
      "metadata": {
        "id": "vLzdWTo7-MGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GHU-lR4y5eki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef57fce4-69f6-4e95-ec1c-f803039a1a2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for removing unnecessary black borders"
      ],
      "metadata": {
        "id": "R1xYMGq9-Q5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_black_borders(image):\n",
        "    y_nonzero, x_nonzero, _ = np.nonzero(image)\n",
        "    return image[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)]    "
      ],
      "metadata": {
        "id": "qqtj1N2x9xS6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Processing the images"
      ],
      "metadata": {
        "id": "ojhCfyP--Y5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  Run this cell once for each satellite  ###\n",
        "\n",
        "# Path must be altered separately for LANDSAT 5, 7 and 8\n",
        "# For LANDSAT 5 : /content/drive/MyDrive/UCD_Research/LANDSAT_5_1984_2011_B4/*.TIF\n",
        "# For LANDSAT 7 : /content/drive/MyDrive/UCD_Research/LANDSAT_7_2001_2021_B4/*.TIF\n",
        "path = glob.glob(\"/content/drive/MyDrive/UCD_Research/LANDSAT_8_2013_2022_B5/*.TIF\")\n",
        "\n",
        "i=1\n",
        "for file in path:\n",
        "  img = cv2.imread(file)\n",
        "  s = file.split(\"_\")\n",
        "  name = \"/content/drive/MyDrive/UCD_Research/Data_LANDSAT_8/\"+s[8]+\".TIF\"\n",
        "  #For LANDSAT 5 : name = \"/content/drive/MyDrive/UCD_Research/Data_LANDSAT_5/\"+s[8]+\".TIF\"\n",
        "  #For LANDSAT 7 : name = \"/content/drive/MyDrive/UCD_Research/Data_LANDSAT_7/\"+s[8]+\".TIF\"\n",
        "  print(name)\n",
        "  \n",
        "  imgb = imutils.rotate(img,angle=14.3) # For LANDSAT 8 images\n",
        "  #imgb = imutils.rotate(img,angle=11.8) # For LANDSAT 5 and LANDSAT 7 images \n",
        "  \n",
        "  imgc = remove_black_borders(imgb)\n",
        "  imgd = cv2.resize(imgc,(1080,1920),interpolation = cv2.INTER_CUBIC)\n",
        "  imge = cv2.imwrite(name,imgd)\n",
        "  print(\"File Number Done : \",i)\n",
        "  i+=1\n",
        "  \n",
        "# 11.8 degree clockwise rotation for LANDSAT 5 and 7 for straightening\n",
        "# 14.3 degree clockwise rotation for LANDSAT 8 for straightening\n",
        "# Writing Images to Google Drive \n",
        "# Cropping the extra black space around image\n"
      ],
      "metadata": {
        "id": "RYitFCXG94bH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "ab8ac93b-a385-4d6f-a06a-eec79c66ad94"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/UCD_Research/Data_LANDSAT_8/20140723.TIF\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-95889ac7c065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m#imgb = imutils.rotate(img,angle=11.8) # For LANDSAT 5 and LANDSAT 7 images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mimgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_black_borders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mimgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1920\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_CUBIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mimge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-6a064c9956bf>\u001b[0m in \u001b[0;36mremove_black_borders\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_black_borders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0my_nonzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_nonzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_nonzero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_nonzero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_nonzero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_nonzero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnonzero\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mnonzero\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m     \"\"\"\n\u001b[0;32m-> 1921\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nonzero'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying Edge Detectors on Satellite Images"
      ],
      "metadata": {
        "id": "UYzicNJw_j5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  Canny Edge Detector  ###\n",
        "\n",
        "# Path must be altered separately for LANDSAT 5, 7 and 8\n",
        "# For LANDSAT 5 : /content/drive/MyDrive/UCD_Research/Data_LANDSAT_5/*.TIF\n",
        "# For LANDSAT 7 : /content/drive/MyDrive/UCD_Research/Data_LANDSAT_7/*.TIF\n",
        "path = glob.glob(\"/content/drive/MyDrive/UCD_Research/Data_LANDSAT_8/*.TIF\")\n",
        "\n",
        "i=1\n",
        "for file in path:\n",
        "  img = cv2.imread(file)\n",
        "  s = file.split(\"_\")\n",
        "  name = \"/content/drive/MyDrive/UCD_Research/Edge_LANDSAT_8/Canny_Edge_\"+s[3][2:10]+\".TIF\"\n",
        "  print(name,end = \"\")\n",
        "  \n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  otsu_threshold, image_result = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "  kernel = np.ones((10, 10), np.uint8)\n",
        "\n",
        "  print(\"File Number Done : \",i)\n",
        "  img[img>otsu_threshold-10] = 255\n",
        "  img[img<=otsu_threshold-10] = 0\n",
        "  \n",
        "  img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "  imgb = cv2.Canny(img,threshold1 = 100, threshold2 = 200)\n",
        "  imga = cv2.imwrite(name,imgb)\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "03bNteN2QIyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###  Sobel Edge Detector  ###\n",
        "\n",
        "# Path must be altered separately for LANDSAT 5, 7 and 8\n",
        "# For LANDSAT 5 : /content/drive/MyDrive/UCD_Research/Data_LANDSAT_5/*.TIF\n",
        "# For LANDSAT 7 : /content/drive/MyDrive/UCD_Research/Data_LANDSAT_7/*.TIF\n",
        "path = glob.glob(\"/content/drive/MyDrive/UCD_Research/Data_LANDSAT_8/*.TIF\")\n",
        "\n",
        "i=1\n",
        "for file in path:\n",
        "  img = cv2.imread(file)\n",
        "  s = file.split(\"_\")\n",
        "  name = \"/content/drive/MyDrive/UCD_Research/Edge_LANDSAT_8/Sobel_Edge_\"+s[3][2:10]+\".TIF\"\n",
        "  print(name,end = \"\")\n",
        "  \n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  otsu_threshold, image_result = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "  kernel = np.ones((10, 10), np.uint8)\n",
        "\n",
        "  print(\"File Number Done : \",i)\n",
        "  img[img>otsu_threshold-10] = 255\n",
        "  img[img<=otsu_threshold-10] = 0\n",
        "  \n",
        "  img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "  sob_x = cv2.Sobel(img, cv2.CV_8U, 1,0, ksize = 5)\n",
        "  sob_y = cv2.Sobel(img, cv2.CV_8U, 0,1, ksize = 5)\n",
        "  imgb = sob_x + sob_y\n",
        "  \n",
        "  imga = cv2.imwrite(name,imgb)\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "l7ws_8PIQFFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###  Scharr Edge Detector  ###\n",
        "\n",
        "# Path must be altered separately for LANDSAT 5, 7 and 8\n",
        "# For LANDSAT 5 : /content/drive/MyDrive/UCD_Research/Data_LANDSAT_5/*.TIF\n",
        "# For LANDSAT 7 : /content/drive/MyDrive/UCD_Research/Data_LANDSAT_7/*.TIF\n",
        "path = glob.glob(\"/content/drive/MyDrive/UCD_Research/Data_LANDSAT_8/*.TIF\")\n",
        "\n",
        "i=1\n",
        "for file in path:\n",
        "  img = cv2.imread(file)\n",
        "  s = file.split(\"_\")\n",
        "  name = \"/content/drive/MyDrive/UCD_Research/Edge_LANDSAT_8/Scharr_Edge_\"+s[3][2:10]+\".TIF\"\n",
        "  print(name,end = \"\")\n",
        "  \n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  otsu_threshold, image_result = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "  kernel = np.ones((10, 10), np.uint8)\n",
        "\n",
        "  print(\"File Number Done : \",i)\n",
        "  img[img>otsu_threshold-10] = 255\n",
        "  img[img<=otsu_threshold-10] = 0\n",
        "  \n",
        "  img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "  schx = cv2.Scharr(img, cv2.CV_8U,1,0)\n",
        "  schy = cv2.Scharr(img, cv2.CV_8U,0,1)\n",
        "  imgb = schx + schy\n",
        "  \n",
        "  imga = cv2.imwrite(name,imgb)\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "reoFdV8FQAci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###  Prewitt Edge Detector  ###\n",
        "\n",
        "# Path must be altered separately for LANDSAT 5, 7 and 8\n",
        "# For LANDSAT 5 : /content/drive/MyDrive/UCD_Research/Data_LANDSAT_5/*.TIF\n",
        "# For LANDSAT 7 : /content/drive/MyDrive/UCD_Research/Data_LANDSAT_7/*.TIF\n",
        "path = glob.glob(\"/content/drive/MyDrive/UCD_Research/Data_LANDSAT_8/*.TIF\")\n",
        "\n",
        "i=1\n",
        "for file in path:\n",
        "  img = cv2.imread(file)\n",
        "  s = file.split(\"_\")\n",
        "  name = \"/content/drive/MyDrive/UCD_Research/Edge_LANDSAT_8/Prewitt_Edge_\"+s[3][2:10]+\".TIF\"\n",
        "  print(name,end = \"\")\n",
        "  \n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  otsu_threshold, image_result = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "  kernel = np.ones((10, 10), np.uint8)\n",
        "\n",
        "  print(\"File Number Done : \",i)\n",
        "  img[img>otsu_threshold-10] = 255\n",
        "  img[img<=otsu_threshold-10] = 0\n",
        "  \n",
        "  img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
        "  kx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]]) \n",
        "  ky = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
        "  img_prewittx = cv2.filter2D(img, -1, kx)\n",
        "  img_prewitty = cv2.filter2D(img, -1, ky)\n",
        "  imgb = img_prewittx + img_prewitty\n",
        "  \n",
        "  imga = cv2.imwrite(name,imgb)\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "A797wf9J-uud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Renaming the files"
      ],
      "metadata": {
        "id": "21B4c0SvS3qI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  Run cell once for each satellite : LANDSAT 5,7 and 8\n",
        "# For LANDSAT 5 : /content/drive/MyDrive/UCD_Research/Edge_LANDSAT_5/*.TIF\n",
        "# For LANDSAT 7 : /content/drive/MyDrive/UCD_Research/Edge_LANDSAT_7/*.TIF\n",
        "path = glob.glob(\"/content/drive/MyDrive/UCD_Research/Edge_LANDSAT_8/*.TIF\")\n",
        "\n",
        "for file in path:\n",
        "  s = file.split(\"/\")\n",
        "  date_name = s[6][-12:-4]\n",
        "  map_name = s[6][:-13]\n",
        "  new_name = s[0]+\"/\"+s[1]+\"/\"+s[2]+\"/\"+s[3]+\"/\"+s[4]+\"/\"+s[5]+\"/\"+date_name+\"_\"+map_name+\".TIF\"\n",
        "  print(new_name)\n",
        "  os.rename(file,new_name)\n"
      ],
      "metadata": {
        "id": "fVOmNznqSyhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Comparison Metrics"
      ],
      "metadata": {
        "id": "2rgRgWWkUC8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "!pip install sewar\n",
        "from sewar.full_ref import rmse, psnr, uqi, ergas, scc, rase, sam, vifp"
      ],
      "metadata": {
        "id": "YruuUd394rvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = []\n",
        "col = ['RMSE', 'PSNR', 'UQI', 'SSIM', 'ERGAS', 'SCC', 'SAM', 'VIFP']\n",
        "data=[]\n",
        "i=0\n",
        "\n",
        "###  Run cell once for each satellite : LANDSAT 5,7 and 8\n",
        "# For LANDSAT 5 : /content/drive/MyDrive/UCD_Research/Edge_LANDSAT_5/*.TIF\n",
        "# For LANDSAT 7 : /content/drive/MyDrive/UCD_Research/Edge_LANDSAT_7/*.TIF\n",
        "path = sorted(glob.glob(\"/content/drive/MyDrive/UCD_Research/Edge_LANDSAT_8/*.TIF\"))\n",
        "\n",
        "for file in path:\n",
        "  s = file.split(\"/\")\n",
        "  pref = s[0]+\"/\"+s[1]+\"/\"+s[2]+\"/\"+s[3]+\"/\"+s[4]+\"/\"+s[5]+\"/\"\n",
        "  if s[6][9] == \"R\":\n",
        "    ref = cv2.imread(file)\n",
        "    date_name = s[6][:8]\n",
        "    can_name = pref+date_name+\"_Edge.TIF\"\n",
        "    sob_name = pref+date_name+\"_Sobel_Edge.TIF\"\n",
        "    sch_name = pref+date_name+\"_Scharr_Edge.TIF\"\n",
        "    pre_name = pref+date_name+\"_Prewitt_Edge.TIF\"\n",
        "    \n",
        "    can = cv2.imread(can_name)\n",
        "    sob = cv2.imread(sob_name)\n",
        "    sch = cv2.imread(sch_name)\n",
        "    pre = cv2.imread(pre_name)\n",
        "\n",
        "    rmse_can = rmse(ref,can)\n",
        "    rmse_sob = rmse(ref,sob)\n",
        "    rmse_sch = rmse(ref,sch)\n",
        "    rmse_pre = rmse(ref,pre)\n",
        "    rmse_ref = rmse(ref,ref)\n",
        "\n",
        "    psnr_can = psnr(ref,can)\n",
        "    psnr_sob = psnr(ref,sob)\n",
        "    psnr_sch = psnr(ref,sch)\n",
        "    psnr_pre = psnr(ref,pre)\n",
        "    psnr_ref = psnr(ref,ref)\n",
        "\n",
        "    uqi_can = uqi(ref,can)\n",
        "    uqi_sob = uqi(ref,sob)\n",
        "    uqi_sch = uqi(ref,sch)\n",
        "    uqi_pre = uqi(ref,pre)\n",
        "    uqi_ref = uqi(ref,ref)\n",
        "\n",
        "    ssim_can = ssim(ref,can,multichannel=True)\n",
        "    ssim_sob = ssim(ref,sob,multichannel=True)\n",
        "    ssim_sch = ssim(ref,sch,multichannel=True)\n",
        "    ssim_pre = ssim(ref,pre,multichannel=True)\n",
        "    ssim_ref = ssim(ref,ref,multichannel=True)\n",
        "\n",
        "    ergas_can = ergas(ref,can)\n",
        "    ergas_sob = ergas(ref,sob)\n",
        "    ergas_sch = ergas(ref,sch)\n",
        "    ergas_pre = ergas(ref,pre)\n",
        "    ergas_ref = ergas(ref,ref)\n",
        "\n",
        "    scc_can = scc(ref,can)\n",
        "    scc_sob = scc(ref,sob)\n",
        "    scc_sch = scc(ref,sch)\n",
        "    scc_pre = scc(ref,pre)\n",
        "    scc_ref = scc(ref,ref)\n",
        "\n",
        "    sam_can = sam(ref,can)\n",
        "    sam_sob = sam(ref,sob)\n",
        "    sam_sch = sam(ref,sch)\n",
        "    sam_pre = sam(ref,pre)\n",
        "    sam_ref = sam(ref,ref)\n",
        "\n",
        "    vifp_can = vifp(ref,can)\n",
        "    vifp_sob = vifp(ref,sob)\n",
        "    vifp_sch = vifp(ref,sch)\n",
        "    vifp_pre = vifp(ref,pre)\n",
        "    vifp_ref = vifp(ref,ref)\n",
        "\n",
        "    row_a = [rmse_ref,psnr_ref,uqi_ref,ssim_ref,ergas_ref,scc_ref,sam_ref,vifp_ref]\n",
        "    row_b = [rmse_can,psnr_can,uqi_can,ssim_can,ergas_can,scc_can,sam_can,vifp_can]\n",
        "    row_c = [rmse_sob,psnr_sob,uqi_sob,ssim_sob,ergas_sob,scc_sob,sam_sob,vifp_sob]\n",
        "    row_d = [rmse_sch,psnr_sch,uqi_sch,ssim_sch,ergas_sch,scc_sch,sam_sch,vifp_sch]\n",
        "    row_e = [rmse_pre,psnr_pre,uqi_pre,ssim_pre,ergas_pre,scc_pre,sam_pre,vifp_pre]\n",
        "    sp = [\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"]\n",
        "\n",
        "    ref_name = 'Reference - ' + date_name\n",
        "    ind.append([ref_name, 'Canny_Image', 'Sobel_Image', 'Scharr_Image', 'Prewitt_Image','_'])\n",
        "    data.append(row_a)\n",
        "    data.append(row_b)\n",
        "    data.append(row_c)\n",
        "    data.append(row_d)\n",
        "    data.append(row_e)\n",
        "    data.append(sp)\n",
        "    i+=1\n",
        "    print(\"Date done: \",date_name)\n",
        "    \n",
        "from itertools import chain\n",
        "flat_ind = list(chain.from_iterable(ind))\n",
        "df1 = pd.DataFrame(data,index=flat_ind,columns=col)\n",
        "df1.to_excel(\"/content/drive/MyDrive/UCD_Research/LANDSAT_8_Edge_Metric.xlsx\")\n",
        "# Change output path to :\n",
        "# For LANDSAT 5 :/content/drive/MyDrive/UCD_Research/LANDSAT_5_Edge_Metric.xlsx\n",
        "# For LANDSAT 7 :/content/drive/MyDrive/UCD_Research/LANDSAT_7_Edge_Metric.xlsx\n",
        "\n"
      ],
      "metadata": {
        "id": "lVzQ2KteUAZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U-Net Model for predicting coastline"
      ],
      "metadata": {
        "id": "fTkobS2MY__D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagecodecs\n",
        "!pip install segmentation-models==1.0.1\n",
        "import tifffile as tiff\n",
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "id": "DdJ4o171Y9er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_img = sorted(glob.glob(\"/content/drive/MyDrive/UCD_Research/Sat_Data/*.TIF\"))\n",
        "path_msk = sorted(glob.glob(\"/content/drive/MyDrive/UCD_Research/Sat_Data/*_mask.tif\"))\n",
        "large_image_stack = []\n",
        "large_msk_stack = []\n",
        "for file in path_msk:\n",
        "  x = cv2.imread(file)\n",
        "  y = cv2.resize(x,(256,256),interpolation = cv2.INTER_CUBIC)\n",
        "  large_msk_stack.append(y)  \n",
        "for file in path_img:\n",
        "  x = cv2.imread(file)\n",
        "  y = cv2.resize(x,(256,256),interpolation = cv2.INTER_CUBIC)\n",
        "  large_image_stack.append(y)"
      ],
      "metadata": {
        "id": "sMEZpWJoZKXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_arr = np.array([i for i in large_image_stack])\n",
        "msk_arr = np.array([i for i in large_msk_stack])"
      ],
      "metadata": {
        "id": "LOMqTXJtZTXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE = 'resnet34'\n",
        "preprocess_input1 = sm.get_preprocessing(BACKBONE)\n",
        "# preprocess input\n",
        "img_arr_pro = preprocess_input1(img_arr)\n",
        "print(img_arr_pro.shape)"
      ],
      "metadata": {
        "id": "i-gJtLoUZXX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(img_arr, msk_arr, test_size = 0.2, random_state = 42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "metadata": {
        "id": "7juCbF_dZYVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate\n",
        "\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)   #Not in the original network. \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)  #Not in the original network\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "#Encoder block: Conv block followed by maxpooling\n",
        "\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p   \n",
        "\n",
        "#Decoder block\n",
        "#skip features gets input from encoder for concatenation\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "#Build Unet using the blocks\n",
        "def build_unet(input_shape, n_classes):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "    b1 = conv_block(p4, 1024) #Bridge\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    if n_classes == 1:  #Binary\n",
        "      activation = 'sigmoid'\n",
        "    else:\n",
        "      activation = 'softmax'\n",
        "\n",
        "    outputs = Conv2D(3, 1, padding=\"same\", activation=activation)(d4)  #Change the activation based on n_classes\n",
        "    print(activation)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "_8PdEW8AZag2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = img_arr.shape[1]\n",
        "IMG_WIDTH  = img_arr.shape[2]\n",
        "IMG_CHANNELS = img_arr.shape[3]\n",
        "\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        "print(input_shape)"
      ],
      "metadata": {
        "id": "snRvSIw9ZgGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = build_unet(input_shape, n_classes=1)\n",
        "model.compile(optimizer=Adam(learning_rate = 1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "hP4Eo3erZh6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size = 16, \n",
        "                    verbose=1, \n",
        "                    epochs=75, \n",
        "                    validation_data=(X_test, y_test), \n",
        "                    shuffle=False)"
      ],
      "metadata": {
        "id": "ncfy6sOJZi30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/UCD_Research/model1_75epochs.hdf5')"
      ],
      "metadata": {
        "id": "1X3Xv2oRZlgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zYlhnVG6ZohH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}